{
    "dataset_dir": "dataset",
    "glove_dir": "glove_embeddings",
    "dataset_path": {
        "train": "dataset/train.txt",
        "validation": "dataset/validation.txt",
        "test": "dataset/test.txt"
    },

    "word2idx_path": "dataset/vocab.json",
    "embeddings": {
        "path": "dataset/embeddings.txt",
        "size": 100
    },

    "class_mapping": {
        "O": 0,
        "B-PER": 1,
        "I-PER": 2,
        "B-ORG": 3,
        "I-ORG": 4,
        "B-LOC": 5,
        "I-LOC": 6,
        "B-MISC": 7,
        "I-MISC": 8
    },

    "vocab_size": 20000,
    "OOV_token": "<unk>",
    "PAD_token": "<padd>",
    "PAD_label": -1,
    "PAD_idx": 1,
    "max_len": 128,

    "use_gpu": true,
    "seed": 42,

    "batch_size": {
        "train": 32,
        "validation": 32,
        "test": 32
    },

    "num_of_transformer_layers": 1,
    "transformer_embedding_dim": 128,
    "transformer_ff_dim": 128,
    "attention_heads": 8,
    "dropout": 0.1,

    "train_config": {
        "num_of_epochs": 20,
        "learning_rate": 0.001,
        "l2_penalty": 0.5,
        "gradient_clipping": 0.5,
        "class_w": [
            1.0, 1.0,
            1.0, 1.0,
            1.0, 1.0,
            1.0, 1.0,
            1.0
        ]
    },

    "model_type": "Transformer"

}

